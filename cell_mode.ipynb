{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPYMUOptsSdE7ApDAHa7dPZ"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Build a model step by step by your custom dataset\n",
        "* get data (download)\n",
        "* (optional) using PIL or matplotlib can visualize img\n",
        "* make train and test directory\n",
        "* create dataset (using torchvsion.datasets) from train and test directory\n",
        "* create Dataloader (using utils.data.DataLoader) from dataset\n",
        "* (optional) using matplotlib check image shape and others.\n",
        "*build model (using torch.nn)\n",
        "* send data to device(cuda- gpu) if available and instantiate an instance (object) for above move\n",
        "* test the model with one image to check model is working fine or not\n",
        "*crate train_step(), test_step() and train () function for training model\n",
        "* create a function to save model\n",
        "* train and evaluate and save the model\n",
        "* visualize model perfomance"
      ],
      "metadata": {
        "id": "xTBTfxBHpJFX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DNDbVyoWn3pH"
      },
      "outputs": [],
      "source": [
        "\n",
        "# 1. get data\n",
        "import os\n",
        "import zipfile\n",
        "from pathlib import Path\n",
        "import requests\n",
        "data_path = Path(\"data/\")\n",
        "image_path = data_path / \"pizza_steak_sushi\"\n",
        "if image_path.is_dir():\n",
        "  print(f\"{image_path} directory exists.\")\n",
        "else:\n",
        "  print(f\"Did not find {image_path} directory, creating one...\")\n",
        "  image_path.mkdir(parents=True, exist_ok = True)\n",
        "with open(data_path / \"pizza_steak_sushi.zip\" , \"wb\") as f:\n",
        "  request = requests.get(\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip\")\n",
        "  print(\"downloading data\")\n",
        "  f.write(request.content)\n",
        "with zipfile.ZipFile(data_path / \"pizza_steak_sushi.zip\", \"r\") as zip_ref:\n",
        "  print(\"unzipping file\")\n",
        "  zip_ref.extractall(image_path)\n",
        "os.remove(data_path / \"pizza_steak_sushi.zip\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python get_data.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wbqp8O1gtdOr",
        "outputId": "3b676ca7-7e26-4817-8f8e-f08513ad7e19"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data/pizza_steak_sushi directory exists.\n",
            "downloading data\n",
            "unzipping file\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#optional visualilze download image"
      ],
      "metadata": {
        "id": "DgnMF-xQGgE4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#2. make train and test directory\n",
        "train_dir = image_path /\"train\"\n",
        "test_dir = image_path /\"test\""
      ],
      "metadata": {
        "id": "4z8XtHt0rwSF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#3.create dataset with transform \n",
        "from torchvision import datasets, transforms\n",
        "data_transform = transforms.Compose([\n",
        "    transforms.Resize((64,64)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "train_data = datasets. ImageFolder(root = train_dir,\n",
        "                                   transform = data_transform,\n",
        "                                   target_transform = None)\n",
        "test_data = datasets.ImageFolder(root = test_dir,\n",
        "                                 transform = data_transform)\n",
        "train_data, test_data\n",
        "class_names = train_data.classes\n",
        "class_names\n",
        "class_dict = train_data.class_to_idx\n",
        "class_dict\n",
        "len(train_data), len(test_data)\n"
      ],
      "metadata": {
        "id": "U5REHZp1r93I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4.turn dataset into DataLoader\n",
        "from torch.utils.data import DataLoader\n",
        "train_dataloader = DataLoader(dataset = train_data,\n",
        "                              batch_size =32,\n",
        "                              num_workers = 1\n",
        "                              shuffle = True)\n",
        "test_dataloader = DataLoader(dataset = test_data,\n",
        "                             batch_size = 32,\n",
        "                             num_workers =1,\n",
        "                             shuffle = False)\n",
        "train_dataloader, test_dataloader\n",
        "#check single image in dataloader\n",
        "img, label = next(iter(train_dataloader))\n",
        "print(f\"Image shape: {img.shape} -> [batch_size, color_channels, height, width]\")\n",
        "print(f\"Label shape: {label.shape}\")"
      ],
      "metadata": {
        "id": "Dr6d7vmttoDc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#5 build a model\n",
        "import torch\n",
        "from torch import nn\n",
        "class TinyVGG(nn.Module):\n",
        "  def __init__(self, input_shape:int, hidden_units: int, output_shape:int):\n",
        "    super().__init__()\n",
        "    self.conv_block_1 = nn.Sequential(\n",
        "        nn.Conv2d(in_channels = input_shape,\n",
        "                  out_channels = hidden_units,\n",
        "                  kernel_size = 3,\n",
        "                  stride =1,\n",
        "                  padding=0),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(in_channels = hidden_units,\n",
        "                  out_channels = hidden_units,\n",
        "                  kernel_size =3,\n",
        "                  stride=1,\n",
        "                  padding=0),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2,\n",
        "                     stride=2)\n",
        "    )\n",
        "    self.conv_block_2 = nn.Sequential(\n",
        "        nn.Conv2d(hidden_units, hidden_units, kernel_size=3, padding=0),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(hidden_units, hidden_units, kernel_size=3, padding=0),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2,\n",
        "                     stride=2)\n",
        "    )\n",
        "    self.classifier = nn.Sequential(\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(in_features = hidden_units *13*13,\n",
        "                  out_features = output_shape)\n",
        "    )\n",
        "    def forward(self, x: torch.Tensor):\n",
        "      #x = self.conv_block_1(x)\n",
        "      #x = self.conv_block_2(x)\n",
        "      #x = self.classifier(x)\n",
        "      return self.classifier(self.conv_block_2(self.conv_block_1(x)))"
      ],
      "metadata": {
        "id": "lFDKlw9IvlkE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. cuda availabe and instantiate an instance of the model\n",
        "import torch\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "torch.manual_seed(42)\n",
        "model_0 = TinyVGG(input_shape =3,\n",
        "                  hidden_units =10,\n",
        "                  output_shape = len(train_data.classes)).to(device)\n",
        "model_0"
      ],
      "metadata": {
        "id": "WKL2hA6jxp1C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. test model by passing one image through our above created model\n",
        "#one image you will get from dataloader\n",
        "img_batch, label_batch = next(iter(train_dataloader))\n",
        "img_single, label_single = img_batch[0].unsqueeze(dim=0), label_batch[0]\n",
        "print(f\"single image shape: {img_single.shape}\\n\")\n",
        "model_0.eval()\n",
        "with torch.inference_mode():\n",
        "  pred = model_0(img_single.to(device))\n",
        "print(f\"output logits:\\n {pred}\\n\")\n",
        "print(f\"output prediction probabilites:\\n {torch.softmax(pred, dim=1)}\\n\")\n",
        "print(f\"output prediction label:\\n {torch.argmax(torch.softmax(pred, dim=1),dim=1)}\\n\")\n",
        "print(f\"Actual label: \\n {label_single}\")\n"
      ],
      "metadata": {
        "id": "b9vFuw8lzB5L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#8. train_step function\n",
        "from typing import Tuple\n",
        "def train_step(model: torch.nn.Module,\n",
        "               dataloader: torch.utils.data.DataLoader,\n",
        "               loss_fn: torch.nn.Module,\n",
        "               optimizer: torch.optim.Optimizer,\n",
        "               device: torch.device):\n",
        "  model.train()\n",
        "  train_loss,train_acc = 0, 0\n",
        "  for batch, (X, y) in enumerate(dataloader):\n",
        "    X, y = X.to(device), y.to(device)\n",
        "    y_pred = model(X)\n",
        "    loss = loss_fn(y_pred, y)\n",
        "    train_loss += loss.item()\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    y_pred_class = torch.argmax(torch.softmax(y_pred, dim=1),dim=1)\n",
        "    train_acc += (y_pred_class ==y).sum().item() /len(y_pred)\n",
        "  train_loss = train_loss /len(dataloader)\n",
        "  train_acc = train_acc /len(dataloader)\n",
        "  return train_loss, train_acc\n"
      ],
      "metadata": {
        "id": "cZc2fYok0kOm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#test loop\n",
        "def test_step(model: torch.nn.Module,\n",
        "              dataloader: torch.utils.data.DataLoader,\n",
        "              loss_fn: torch.nn.Module,\n",
        "              device: torch.device):\n",
        "  model.eval()\n",
        "  test_loss, test_acc = 0,0\n",
        "  with torch.inference_mode():\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "      X, y = X.to(device), y.to(device)\n",
        "      y_pred = model(X)\n",
        "      loss = loss_fn(y_pred, y)\n",
        "      test_loss += loss.item()\n",
        "      y_pred_class = torch.argmax(torch.softmac(y_pred, dim=1), dim=1)\n",
        "      test_acc += (y_pred_class ==y).sum().item() / len(y_pred)\n",
        "  test_loss = test_loss /len(dataloader)\n",
        "  test_acc = test_acc /len(dataloader)\n",
        "  return test_loss, test_acc"
      ],
      "metadata": {
        "id": "xhW3GHcC2mx9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#now combine train_step and test_step functin inside a function\n",
        "from typing import Dict, List\n",
        "from tqdm.auto import tqdm\n",
        "def train(model: torch.nn.Module,\n",
        "           train_dataloader: torch.utils.data.DataLoader,\n",
        "           test_dataloader: torch.utils.data.DataLoader,\n",
        "           optimizer: torch.optim.Optimizer,\n",
        "           loss_fn: torch.nn.Module,\n",
        "           epochs: int,\n",
        "           device: torch.device):\n",
        "   results = {\"train_loss\" :[],\n",
        "              \"train_acc\" : [],\n",
        "              \"test_loss\" :[],\n",
        "              \"test_acc\" : []\n",
        "              }\n",
        "    #loop above function\n",
        "   for epoch in tqdm(range(epochs)):\n",
        "      train_loss, train_acc = train_step(model=model,\n",
        "                                         dataloader = train_dataloader,\n",
        "                                         loss_fn = loss_fn,\n",
        "                                         optimizer = optimizer,\n",
        "                                         device = device)\n",
        "      test_loss, test_acc = test_step(model = model,\n",
        "                                      dataloader = test_dataloader,\n",
        "                                      loss_fn = loss_fn,\n",
        "                                      device = device)\n",
        "      print(f\"Epoch: {epoch+1} | \"\n",
        "            f\"train_loss: {train_loss:.4f}  | \"\n",
        "            f\"train_acc:  {train_acc: .4f}  | \"\n",
        "            f\"test_loss:  {test_loss: .4f}  |\"\n",
        "            f\"test_acc:   {test_acc: .4f}\" )\n",
        "      results[\"train_loss\"].append(train_loss)\n",
        "      results[\"train_acc\"].append(train_acc)\n",
        "      results[\"test_loss\"].append(test_loss)\n",
        "      results[\"test_acc\"].append(test_acc)\n",
        "   return results\n",
        "  "
      ],
      "metadata": {
        "id": "aVtDloCl4Vp3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#9. save the model\n",
        "def save_model(model: torch.nn.Module,\n",
        "               target_dir: str,\n",
        "               model_name: str):\n",
        "  target_dir_path = Path(target_dir)\n",
        "  target_dir_path.mkdir(parents = True,\n",
        "                        exist_ok = True)\n",
        "  assert model_name.endswith(\".pth\") or model_name.endswith(\".pt\"), \"model_name should end with '.pt' or '.pth'\"\n",
        "  model_save_path = target_dir_path /model_name\n",
        "  print(f\"[Info] saving model to: {model_save_path}\")\n",
        "  torch.save(obj=model.state_dict(),\n",
        "             f=model_save_path)  "
      ],
      "metadata": {
        "id": "aHXT-oUkCUPl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#10. train, evaluate and save the model\n",
        "torch.manual_seed(42)\n",
        "torch.cusa.manual_seed(42)\n",
        "NUM_EPOCHS = 5\n",
        "model_0 = TinyVGG(input_shape=3,\n",
        "                  hidden_units =10,\n",
        "                  output_shape = len(train_data.classes)).to(device)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(params=model_0.parameters(), lr = 0.001)\n",
        "from timeit import default_timer as timer\n",
        "start_time = timer()\n",
        "model_0_results = train(model=model_0,\n",
        "                        train_dataloader = train_dataloader,\n",
        "                        test_dataloader = test_dataloader,\n",
        "                        optimizer = optimizer,\n",
        "                        loss_fn = loss_fn,\n",
        "                        epochs = NUM_EPOCHS,\n",
        "                        device = device)\n",
        "end_time = timer()\n",
        "print(f\"[info] total training time : {end_time - start_time:.3f} seconds\")\n",
        "save_model(model=model_0,\n",
        "           target_dir = \"models\",\n",
        "           model_name = \"05_going_modular_cell_mode_tinyvgg_model.pth\")\n",
        "\n"
      ],
      "metadata": {
        "id": "UVfLaLSXEeJj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#11 visualization test loss curve and accuracy curve"
      ],
      "metadata": {
        "id": "fzETazkDGWwF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}